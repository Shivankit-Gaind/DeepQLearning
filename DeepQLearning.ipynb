{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "#For using environments of atari games\n",
    "import tensorflow as tf\n",
    "#For building CNNs\n",
    "from PIL import Image\n",
    "#For some image processing\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-10 00:07:50,084] Making new env: Breakout-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing the environment by choosing random actions\n",
    "for i in range(2):\n",
    "    state = env.reset()\n",
    "    for t in range(500):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        state,reward,done,_ = env.step(action)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(state,show = False):\n",
    "    if len(state.shape) == 4:\n",
    "        state = state[0]\n",
    "    img = Image.fromarray(state.astype('uint8'), 'RGB')\n",
    "    img = img.convert('LA')\n",
    "    img = img.crop((0,34,160,192))\n",
    "    img = img.resize((84,84))\n",
    "    img = np.array(img,np.float32)\n",
    "    img = img[:,:,0]\n",
    "    if show:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    img = np.stack([img] * 4, axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvtQggy81yOBLDfofAqHuTJpUXMwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f387f414470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        ..., \n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.]],\n",
       "\n",
       "       [[ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        ..., \n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.]],\n",
       "\n",
       "       [[ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        ..., \n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        ..., \n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.],\n",
       "        [ 142.,  142.,  142.,  142.]],\n",
       "\n",
       "       [[ 127.,  127.,  127.,  127.],\n",
       "        [ 127.,  127.,  127.,  127.],\n",
       "        [ 127.,  127.,  127.,  127.],\n",
       "        ..., \n",
       "        [ 110.,  110.,  110.,  110.],\n",
       "        [ 110.,  110.,  110.,  110.],\n",
       "        [ 110.,  110.,  110.,  110.]],\n",
       "\n",
       "       [[ 127.,  127.,  127.,  127.],\n",
       "        [ 127.,  127.,  127.,  127.],\n",
       "        [ 127.,  127.,  127.,  127.],\n",
       "        ..., \n",
       "        [ 110.,  110.,  110.,  110.],\n",
       "        [ 110.,  110.,  110.,  110.],\n",
       "        [ 110.,  110.,  110.,  110.]]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "preprocess(state,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self,batch_size,scope):\n",
    "        self.batch_size = batch_size\n",
    "        self.scope = scope\n",
    "        self.layers = {}\n",
    "        self.model()\n",
    "    \n",
    "    def model(self):\n",
    "        #tf.reset_default_graph()\n",
    "        with tf.variable_scope(self.scope):\n",
    "            #Placeholders for input(state), output(Value function) and actions\n",
    "            self.input = tf.placeholder(tf.float32,shape=[None,84,84,4])\n",
    "            self.output = tf.placeholder(tf.float32,shape=[None])\n",
    "            self.actions = tf.placeholder(tf.int32,shape = [None])\n",
    "            \n",
    "            #Convolutional Layers\n",
    "            \n",
    "            initializer = tf.contrib.layers.xavier_initializer()\n",
    "            self.layers['a1'] = tf.layers.conv2d(self.input,filters = 32,kernel_size=8,strides=4,\n",
    "                                                 padding = 'SAME',kernel_initializer = initializer,name='conv1')\n",
    "            self.layers['a1'] = tf.nn.relu(self.layers['a1'],name='relu1')\n",
    "            self.layers['a2'] = tf.layers.conv2d(self.layers['a1'], filters= 64, kernel_size = 4, strides = 2,\n",
    "                                                 padding = 'SAME', kernel_initializer = initializer,name='conv2')\n",
    "            self.layers['a2'] = tf.nn.relu(self.layers['a2'],name='relu2')\n",
    "            self.layers['a3'] = tf.layers.conv2d(self.layers['a2'],filters=64,kernel_size=3, strides=1,\n",
    "                                                 padding = 'SAME',kernel_initializer = initializer, name='conv3')\n",
    "            self.layers['a3'] = tf.nn.relu(self.layers['a3'],name='relu3')\n",
    "            \n",
    "            #Fully connected Layers\n",
    "            shape = self.layers['a3'].get_shape().as_list()\n",
    "            dims = shape[1]*shape[2]*shape[3]\n",
    "            self.layers['a3'] = tf.reshape(self.layers['a3'],shape=[-1,dims],name='flat')\n",
    "            self.layers['a4'] = tf.layers.dense(self.layers['a3'],512,kernel_initializer = initializer,name='fc1')\n",
    "            self.layers['a4'] = tf.nn.relu(self.layers['a4'],name='relu4')\n",
    "            self.layers['output'] = tf.layers.dense(self.layers['a4'],4,kernel_initializer = initializer,name='output')\n",
    "            \n",
    "            #Selecting values corresponding to the actions\n",
    "            #inds = tf.concat([tf.reshape(tf.range(self.batch_size),[1,self.batch_size]),tf.reshape(self.actions,[1,self.batch_size])],axis=0)\n",
    "            #inds = tf.transpose(inds)\n",
    "            #self.value_funcs = tf.gather_nd(self.layers['output'],inds)\n",
    "            \n",
    "            inds = tf.range(self.batch_size) * tf.shape(self.layers['output'])[1] + self.actions\n",
    "            self.value_funcs = tf.gather(tf.reshape(self.layers['output'], [-1]), inds)\n",
    "\n",
    "            \n",
    "            #Finding the loss\n",
    "            self.loss = tf.reduce_mean((self.output - self.value_funcs)**2)\n",
    "            \n",
    "            #Global Step\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            #Optimizer\n",
    "            self.opti = tf.train.RMSPropOptimizer(learning_rate=0.00025,momentum=0.95,decay=0.95,epsilon=1e-8).minimize(self.loss,self.global_step)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_cnn_params(cnn1,cnn2):\n",
    "    params_cnn1 = []\n",
    "    params_cnn2 = []\n",
    "    for var in tf.trainable_variables():\n",
    "        if var.name.startswith(cnn1.scope):\n",
    "            params_cnn1.append(var)\n",
    "        elif var.name.startswith(cnn2.scope):\n",
    "            params_cnn2.append(var)\n",
    "    copy_op = []\n",
    "    for i in range(len(params_cnn1)):\n",
    "        copy_op.append(params_cnn2[i].assign(params_cnn1[i]))\n",
    "    \n",
    "    return copy_op\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e1_params = [t for t in tf.trainable_variables() if t.name.startswith(q.scope)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'tes1/conv1/kernel:0' shape=(8, 8, 4, 32) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/conv1/bias:0' shape=(32,) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/conv2/kernel:0' shape=(4, 4, 32, 64) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/conv3/bias:0' shape=(64,) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/fc1/kernel:0' shape=(7744, 512) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/fc1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/output/kernel:0' shape=(512, 4) dtype=float32_ref>\n",
      " <tf.Variable 'tes1/output/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "[<tf.Variable 'tes2/conv1/kernel:0' shape=(8, 8, 4, 32) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/conv1/bias:0' shape=(32,) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/conv2/kernel:0' shape=(4, 4, 32, 64) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/conv3/bias:0' shape=(64,) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/fc1/kernel:0' shape=(7744, 512) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/fc1/bias:0' shape=(512,) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/output/kernel:0' shape=(512, 4) dtype=float32_ref>\n",
      " <tf.Variable 'tes2/output/bias:0' shape=(4,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "q1 = DQN(32,'tes1')\n",
    "q2 =  DQN(32,'tes2')\n",
    "copy_op = copy_cnn_params(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Assign:0' shape=(8, 8, 4, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_2:0' shape=(4, 4, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_3:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_4:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_5:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_6:0' shape=(7744, 512) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_7:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_8:0' shape=(512, 4) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_9:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_func(state,sess,epsilon,num_actions,action_cnn):\n",
    "    state = state[np.newaxis,:]\n",
    "    preds = sess.run(action_cnn.layers['output'],{action_cnn.input:state})\n",
    "    p = np.ones(num_actions)*epsilon/num_actions\n",
    "    greedy_action = np.argmax(preds)\n",
    "    p[greedy_action] += 1 - epsilon\n",
    "    return p\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DQL(env,env1,sess,action_cnn,target_cnn,num_episodes,epsilons,discount_factor,replay_mem_size,batch_size,C,record,decay_rate):\n",
    "    decay_count = tf.train.global_step(sess,action_cnn.global_step)\n",
    "    print(decay_count)\n",
    "    #Initializing Replay memory\n",
    "    D = []\n",
    "    state = env.reset()\n",
    "    print(\"populating replay memory\")\n",
    "    for i in range(replay_mem_size//10):\n",
    "        state = preprocess(state)\n",
    "        action_probs = policy_func(state,sess,epsilons[min(decay_count,decay_rate-1)],4,action_cnn)\n",
    "        action = np.random.choice(np.arange(len(action_probs)), p = action_probs)\n",
    "        new_state,reward,done,_ = env.step(action)\n",
    "        D.append((preprocess(state),action,reward,preprocess(new_state),done))\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "        else:\n",
    "            state = new_state\n",
    "            \n",
    "    print(\"Been There Done That\")\n",
    "    saver = tf.train.Saver()\n",
    "    # Load a previous checkpoint if we find one\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    #env = Monitor(env, directory='videos', video_callable=lambda count: count % record == 0, resume=True)\n",
    "    losses = []        \n",
    "    for i in range(num_episodes):\n",
    "        saver.save(sess, 'checkpoints/DQN')\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        decay_count = tf.train.global_step(sess,action_cnn.global_step)\n",
    "        print(\"episode: \",i,\"global_step: \",decay_count)\n",
    "        ep_reward = 0\n",
    "        while done == False:\n",
    "            state = preprocess(state)\n",
    "            action_probs = policy_func(state,sess,epsilons[min(decay_count,decay_rate-1)],4,action_cnn)\n",
    "            action = np.random.choice(np.arange(len(action_probs)), p = action_probs)\n",
    "            new_state,reward,done,_ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            new_state = preprocess(new_state)\n",
    "            if(len(D)==replay_mem_size):\n",
    "                D.pop(0)\n",
    "            D.append((state,action,reward,new_state,done))\n",
    "            \n",
    "            batch = random.sample(D,batch_size)\n",
    "            states = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            new_states = []\n",
    "            dones = []\n",
    "            \n",
    "            for a in batch:\n",
    "                states.append(a[0])\n",
    "                actions.append(a[1])\n",
    "                rewards.append(a[2])\n",
    "                new_states.append(a[3])\n",
    "                dones.append(a[4])\n",
    "            \n",
    "            flags = np.invert(dones)\n",
    "            y = rewards + flags*discount_factor*np.max(sess.run(target_cnn.layers['output'],\n",
    "                                                                {target_cnn.input:new_states}),axis=1)\n",
    "            loss,_ = sess.run([action_cnn.loss,action_cnn.opti],{action_cnn.input:states,action_cnn.output:y,\n",
    "                                                                 action_cnn.actions:actions})\n",
    "            losses.append(loss)\n",
    "            if decay_count%C == 0:\n",
    "                print(loss)\n",
    "                copy_op = copy_cnn_params(action_cnn,target_cnn)\n",
    "                sess.run(copy_op)\n",
    "        \n",
    "            new_state = state\n",
    "        print(\"Reward: \",ep_reward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.invert([True,False])*[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabir/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "action_cnn = DQN(BATCH_SIZE,'action_cnn')\n",
    "target_cnn = DQN(BATCH_SIZE,'target_cnn')\n",
    "decay_rate = 500000\n",
    "epsilons = np.linspace(1,0.1,decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating replay memory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-eca8548ed3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     step = DQL(env,env1,sess,action_cnn,target_cnn,10000,epsilons,discount_factor=0.99,replay_mem_size=500000,\n\u001b[0;32m----> 6\u001b[0;31m         batch_size=BATCH_SIZE,C=10000,record=50,decay_rate=decay_rate)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fcb4f642e8b9>\u001b[0m in \u001b[0;36mDQL\u001b[0;34m(env, env1, sess, action_cnn, target_cnn, num_episodes, epsilons, discount_factor, replay_mem_size, batch_size, C, record, decay_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cae27cbba2a7>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdither\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    copy_op = copy_cnn_params(action_cnn,target_cnn)\n",
    "    sess.run(copy_op)\n",
    "    DQL(env,env1,sess,action_cnn,target_cnn,10000,epsilons,discount_factor=0.99,replay_mem_size=500000,\n",
    "        batch_size=BATCH_SIZE,C=10000,record=50,decay_rate=decay_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/DQN\n",
      "Loading model checkpoint checkpoints/DQN...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/DQN\n",
      "Playing\n",
      "Game Over\n",
      "Played\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    checkpoint = tf.train.latest_checkpoint('checkpoints/')\n",
    "    print(checkpoint)\n",
    "    if checkpoint:\n",
    "        print(\"Loading model checkpoint {}...\\n\".format(checkpoint))\n",
    "        saver.restore(sess, checkpoint)\n",
    "    #ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/'))\n",
    "    #if ckpt and ckpt.model_checkpoint_path:\n",
    "    #    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    print(\"Playing\")\n",
    "    state = env1.reset()\n",
    "    for t in range(50000):\n",
    "        state = preprocess(state)\n",
    "        env1.render()\n",
    "        action_probs = policy_func(state,sess,epsilons[decay_rate-1],4,action_cnn)\n",
    "        action = np.random.choice(np.arange(len(action_probs)), p = action_probs)\n",
    "        state,reward,done,_ = env1.step(action)\n",
    "        if done:\n",
    "            print(\"Game Over\")\n",
    "            break\n",
    "    print(\"Played\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
